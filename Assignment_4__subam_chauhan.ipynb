{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Schauhan21/DL/blob/main/Assignment_4__subam_chauhan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_r54UV910B6"
      },
      "source": [
        "# 521153S, Deep Learning assignment 4: Improvements on Convolutional Neural Networks \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQqEq0Em10B_"
      },
      "source": [
        "## Outline \n",
        "#### In this assignment, you will learn:\n",
        "* Load training/validation/testing dataset from csv file. \n",
        "* Building a Convolutional Neural Network (CNN) in Pytorch.\n",
        "* Use the resnet-18 Pytorch model.\n",
        "* Using tensorboard.\n",
        "* Save and load your model.\n",
        "* Training and testing your CNN in Pytorch.\n",
        "\n",
        "#### Tasks (<span style=\"color:green\">15 points </span>)\n",
        "* **Part 1.** Writing a custom dataset based on [**Fashion-MNIST**](https://github.com/zalandoresearch/fashion-mnist). Spliting the whole dataset into 3 parts: training, validation and testing. (<span style=\"color:green\">5.0 points</span>)\n",
        "    * 1.1. Define a Dataset class <br>\n",
        "    * 1.2. Dataset checking (<span style=\"color:green\">2.0 points</span>) <br>\n",
        "    * 1.3. Build our custom data augmentation <br>\n",
        "    * 1.4. Load the training/validation/testing data to Dataloader (<span style=\"color:green\">2.0 points</span>) <br>\n",
        "    * 1.5. Use functions define in **Part 1.4** to actually create our training/validation/testing DataLoaders (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "* **Part 2.** Build a CNN on your own. (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "    * 2.1 Modify model from assignment 3 (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "    * 2.2 ResNet-18\n",
        "* **Part 3.** Train and test your CNN model (<span style=\"color:green\">9.0 points</span>)\n",
        "    * 3.1. Create functions for train and evaluation <br>\n",
        "    * 3.2. Training and tensorboard log  (<span style=\"color:green\">3.5 points</span>) <br>\n",
        "    * 3.3. Tensorboard visualization  (<span style=\"color:green\">1.0 point</span>) <br>\n",
        "    * 3.4. Train and test your network (<span style=\"color:green\">1.0 points</span>) <br>\n",
        "    * 3.5. Train and test using the resnet-18 model (<span style=\"color:green\">1.5 points</span>) <br>\n",
        "    * 3.6. Load a pretrained weights and report the accuracy from **Assignment_4_load_model.ipynb** (<span style=\"color:green\">1.5 points</span>) <br>\n",
        "    * 3.7. Ideas on improving the testing accuracy (<span style=\"color:green\">0.5 points</span>) <br>\n",
        "\n",
        "\n",
        "#### Environment\n",
        "Python 3, Numpy, matplotlib, torch, torchvision, pandas, tensorboard  \n",
        "* To install needed Python packages, run:  \n",
        "**pip install tensorboard pandas future**\n",
        "\n",
        "#### Dataset\n",
        "* [**Fashion-MNIST**](https://github.com/zalandoresearch/fashion-mnist)\n",
        "is a dataset of Zalando's article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Here we are to split the 60,000 images in the predefined training set into a new training set with 50,000 images and a validation set with 10,000 images. Each example is a 28x28 grayscale image, associated with a label from 10 classes. We intend Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training, validation and testing splits. Using the Fashion-MNIST give you more room to wiggle your experiments.\n",
        "\n",
        "#### Hints\n",
        "* To find the place where you have to insert your solution, hit **Crtl + F** and search for **TODO:** . You are <span style=\"color:red\">**NOT**</span> supposed to modify the codes from other parts.\n",
        "* Be careful with the shapes of the tensors flowing through the CNN model, making all the operations has compatible inputs and outputs. \n",
        "* In case your computer support CUDA, you can add .cuda() to your model, loss and data to use your GPU. Refer to our [pytorch tutorial](https://moodle.oulu.fi/pluginfile.php/189345/mod_resource/content/3/Pytorch%20Tutorial%20for%20Deep%20Learning%202019.pdf) to see this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd6LeWJg10CC"
      },
      "source": [
        "## Part 1. Write your own custom dataset with Pytorch (<span style=\"color:green\">5 points</span>)\n",
        "**Requirement**: Download the Fashion-MNIST dataset, which contains 60,000 images in the predefined training set and 10,000 images in the testing set. Our goal is to write our custom dataset. The training/validation/testing data were already split as 50K/10K/10K, respectively. **Specifically, there is the same number of images for each class, both in the new training set and the validation set.** I.e., in the new training set, which has in total 10 classes and 50,000 image samples, each class has 5000 image samples while in the validation set, each class has 1000 samples.\n",
        "+ In assignment 3, we loaded the whole training + validation + testing data into the memory. This, in turn, can quickly swallow your memory.\n",
        "+ In practice, we usually load data by batch during training or testing time, which consumes much less memory. In this assignment, our data was structured like this:  \n",
        "(folder)fashion_mnist_extracted  \n",
        "---(folder)train_images  \n",
        "------(folder)Ankle_boot  \n",
        "---------0000000.png  \n",
        "---------0000001.png  \n",
        "------(folder)Bag  \n",
        "------(folder)Coat  \n",
        ".  \n",
        ".  \n",
        "---(folder)val_images  \n",
        "------(folder)Ankle_boot  \n",
        "---------0000000.png  \n",
        "---------0000001.png  \n",
        "------(folder)Bag  \n",
        "------(folder)Coat  \n",
        ".  \n",
        ".  \n",
        "---(folder)test_images  \n",
        "------(folder)Ankle_boot  \n",
        "---------0000000.png  \n",
        "---------0000001.png  \n",
        "------(folder)Bag  \n",
        "------(folder)Coat  \n",
        ".  \n",
        ".  \n",
        "---train.csv  \n",
        "---val.csv  \n",
        "---test.csv  \n",
        "that our **.csv files** contains the image paths and their corresponding labels. Their content look like this:  \n",
        "./fashion_mnist_extracted/train_images/Dress/0000012.png,3  \n",
        "./fashion_mnist_extracted/train_images/T_shirt/0000006.png,0  \n",
        "./fashion_mnist_extracted/train_images/Sneaker/0000004.png,7  \n",
        "./fashion_mnist_extracted/train_images/Trouser/0000003.png,1  \n",
        "./fashion_mnist_extracted/train_images/Shirt/0000005.png,6  \n",
        "<span style=\"color:purple\"> ***You should take a look at the data in folder `fashion_mnist_extracted`*** </span>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3u3tR_K10CE"
      },
      "source": [
        "### Part 1.1. Define a Dataset class\n",
        "As in previous assignment, torch.utils.data.Dataset is an abstract class representing a dataset. Our **FashionMNISTDataset** dataset should inherit `torch.utils.data.Dataset` and override the following methods:\n",
        "* `__init__` defines additional attributes for our dataset.\n",
        "* `__len__` so that len(dataset) returns the size of the dataset.\n",
        "* `__getitem__` to support the indexing such that dataset[i] can be used to get ith sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dk6HHJjF10CF",
        "outputId": "82a56eb5-0fc7-4162-d274-7e9d59d6a258"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data was already downloaded and extracted!\n",
            "GPU_available=True\n"
          ]
        }
      ],
      "source": [
        "# import necessary packages\n",
        "import os, time\n",
        "import torch \n",
        "import requests, zipfile, sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from utils import download_fm, get_preds_figure\n",
        "import torchvision\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils\n",
        "import random, matplotlib\n",
        "import pandas as pd\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "download_fm('./')\n",
        "\n",
        "# Check does your computer support using GPU\n",
        "print(\"GPU_available={}\".format(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba7X_O7_10CG"
      },
      "source": [
        "Let’s create a dataset class for our fashion MNIST dataset. We will download the dataset from google drive following Assignment 2 and 3. \n",
        "* **FashionMNISTDataset** takes in a csv_file and a compose torchvision.transforms to perform data augmentation.  \n",
        "* **__getitem__() function** loads a specific data sample, transform and convert it to pytorch tensor and return a dictionary that contains the image and its label.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuDVrJB110CH"
      },
      "outputs": [],
      "source": [
        "class FashionMNISTDataset(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        # Read the csv file\n",
        "        self.frame = pd.read_csv(csv_file, header=None)\n",
        "        self.transform = transform\n",
        "        \n",
        "        self.label_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_name = self.frame.iloc[idx, 0]\n",
        "        image = Image.open(image_name)\n",
        "        \n",
        "        label = self.frame.iloc[idx, 1]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        sample = {'image': image, 'label': label}\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGObgxY410CI"
      },
      "source": [
        "### Part 1.2. Dataset checking (<span style=\"color:green\">2.0 points</span>)\n",
        "Similar to assignment 3, randomly show some images in training, validation and testing data and check if the images have correct labels. We also check the number of images for each class, to make sure the dataset created correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "AKOfgOAG10CI"
      },
      "outputs": [],
      "source": [
        "# Create a train_set from the train.csv file without any transformations\n",
        "train_set = FashionMNISTDataset(csv_file='./fashion_mnist_extracted/train.csv', transform=None)\n",
        "\n",
        "num_to_show = 5\n",
        "idx = np.random.choice(range(len(train_set)), num_to_show, replace=False)\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "for i in range(len(idx)):\n",
        "    image, label = train_set[idx[i]]['image'], train_set[idx[i]]['label']\n",
        "    label_name = train_set.label_names[label]\n",
        "\n",
        "    ax = plt.subplot(1, num_to_show, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ax.set_title('class #{}'.format(label_name))\n",
        "    ax.axis('off')\n",
        "    plt.imshow(np.asarray(image), cmap=matplotlib.cm.binary)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Print the number of total images in the training set\n",
        "print('total number of training set: {}'.format(len(train_set)))\n",
        "\n",
        "# Print the number of images per class in the training set\n",
        "class_num_train = np.zeros(10, dtype=np.int32)\n",
        "for x in train_set:\n",
        "    class_num_train[x['label']] += 1\n",
        "for i in range(10):\n",
        "    print('numer of images for class {}: {}'.format(train_set.label_names[i], class_num_train[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCzQVEKv10CJ"
      },
      "outputs": [],
      "source": [
        "# TODO:load and checking validation data (1 point)\n",
        "# Create a valid_set from the val.csv file without any transformations\n",
        "valid_set = FashionMINSTDataset(csv_file='./fashion_mnist_extracted/test.csv', transform=None)\n",
        "num_to_show = 5\n",
        "idx = np.random.choice(range(len(valid_set)), num_to_show, replace=False)\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "# TODO: show plots\n",
        "for i in range(len(idx)):\n",
        "    image, label = valid_set[idx[i]]['image'], valid_set[idx[i]]['label']\n",
        "    label_name = valid_set.label_names[label]\n",
        "    vs = plt.subplot(1, num_to_show, i + 1)\n",
        "    plt.tight_layout()\n",
        "    vs.set_title('class #{}'.format(label_name))\n",
        "    vs.axis('off')\n",
        "    plt.imshow(np.asarray(image), cmap=matplotlib.cm.binary)\n",
        "    plt.show()\n",
        "    \n",
        "# TODO: Print the number of total images in the validation set  \n",
        "print('total number of valid set: {}'.format(len(valid_set)))\n",
        "\n",
        "# TODO: Print the number of images per class in the validation set\n",
        "class_num_val = np.zeros(10, dtype=np.int32)\n",
        "for x in valid_set:\n",
        "    class_num_val[x['label']] += 1\n",
        "for i in range(10):\n",
        "    print('number of images for class {}: {}'.format(valid_set.label_name[i], class_num_val[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihjGaxNJ10CJ"
      },
      "outputs": [],
      "source": [
        "# TODO: checking testing data (1 point)\n",
        "# Create a test_set from the test.csv file without any transformations\n",
        "test_set =  FashionMNISTDataset(csv_file='./fashion_mnist_extracted/test.csv', transform=None)\n",
        "num_to_show = 5\n",
        "idx = np.random.choice(range(len(test_set)), num_to_show, replace=False)\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "# TODO: show plots\n",
        "for i in range(len(idx)):\n",
        "    image, label = test_set[idx[i]]['image'], valid_set[idx[i]]['label']\n",
        "    label_name = test_set.label_names[label]\n",
        "    ts=plt.subplot(1, num_to_show, i + 1)\n",
        "    plt.tight_layout()\n",
        "    ts.set_title('class #{}'.format(label_name))\n",
        "    ts.axis('off')\n",
        "    plt.imshow(np.asarray(image), cmap=matplotlib.cm.binary)\n",
        "    plt.show()\n",
        "\n",
        "# TODO: Print the number of total images in the testing set    \n",
        "print('total number of test set: {}'.format(len(test_set)))\n",
        "    \n",
        "# TODO: Print the number of images per class in the testing set\n",
        "class_num_test = np.zeros(10, dtype=np.int32)\n",
        "for x in test_set:\n",
        "    class_num_test[x['label']] += 1\n",
        "for i in range(10):\n",
        "    print('number of images for class {}: {}'.format(test_set.label_name[i], class_num_test[i]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A1pZWXQ10CK"
      },
      "source": [
        "### Part 1.3. Build our custom data augmentation\n",
        "\n",
        "We can define a custom data transformation for data augmentation namely **RandomWindowDrop**. There are 50%/50% chance that it will randomly cut a square window inside our image or horizontally flip the image.  \n",
        "* Randomly cut a square window.\n",
        "\n",
        "* Random horizontal flip.\n",
        "\n",
        "Perform data augmentation during training improve the performance of our model. As we will see later, our model performance will increase from 90% -> 91% when applying **RandomWindowDrop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agxrEA_l10CK"
      },
      "outputs": [],
      "source": [
        "class RandomWindowDrop(object):\n",
        "    def __init__(self, window_size):\n",
        "        assert isinstance(window_size, (int, tuple))\n",
        "        if isinstance(window_size, int):\n",
        "            self.window_size = (window_size, window_size)\n",
        "        else:\n",
        "            assert len(window_size) == 2\n",
        "            self.window_size = window_size\n",
        "        \n",
        "        # Define a horizontalFlip\n",
        "        self.trans = transforms.RandomHorizontalFlip(p=1.0)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        image = sample\n",
        "\n",
        "        # Perform either RandomWindowDrop or RandomHorizontalFlip\n",
        "        if random.random() < 0.5:\n",
        "            h, w = image.size\n",
        "            imagePixels = image.load()\n",
        "            top = np.random.randint(self.window_size[0], h - self.window_size[0])\n",
        "            left = np.random.randint(self.window_size[1], w - self.window_size[1])\n",
        "            for i in range(top, top+self.window_size[0], 1):\n",
        "                for j in range(left, left+self.window_size[1], 1):   \n",
        "                    imagePixels[i, j] = 0\n",
        "        else:\n",
        "            image = self.trans(image)\n",
        "\n",
        "        return image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTEeWVYy10CL"
      },
      "source": [
        "### Part 1.4. Load the training/validation/testing data to Dataloader (<span style=\"color:green\">2 points</span>)  \n",
        "Here, we declare functions that use to load our training/validation/testing data using the our defined **FashionMNISTDataset**. \n",
        "* To create a DataLoader, we declare functions that will load our files and output DataLoaders. As defined earlier, our **FashionMNISTDataset** takes in a csv_file and a list of transformation to create the Dataset. This Dataset is used to create the DataLoader.\n",
        "* For training, we will create train_loader using **train.csv** with list of transformations (later you will be askd to insert more transformation in **Part 3.5**)\n",
        "    * RandomWindowDrop(6)\n",
        "    * transforms.ToTensor()\n",
        "    * transforms.Normalize(__normalize_stats['mean'], __normalize_stats['std'])\n",
        "    \n",
        "* For validation, we will create valid_loader using **val.csv** with list of transformations (later you will be asked to insert more transformation in **Part 3.5**)\n",
        "    * transforms.ToTensor()\n",
        "    * transforms.Normalize(__normalize_stats['mean'], __normalize_stats['std'])\n",
        "    \n",
        "* For testing, we will create test_loader using **test.csv** with list of transformations (later you will be asked to insert more transformation in **Part 3.5**)\n",
        "    * transforms.ToTensor()\n",
        "    * transforms.Normalize(__normalize_stats['mean'], __normalize_stats['std'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90jGaGnZ10CL"
      },
      "outputs": [],
      "source": [
        "def getTrainingData(csv_file='./fashion_mnist_extracted/train.csv', batch_size=64, num_workers=0):\n",
        "    __normalize_stats = {'mean': [0.5], 'std': [0.5]}\n",
        "\n",
        "    # transforms.Compose create a list of transformations\n",
        "    transformed_training = FashionMNISTDataset(csv_file=csv_file,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            RandomWindowDrop(6),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(__normalize_stats['mean'],\n",
        "                                                      __normalize_stats['std'])\n",
        "                                        ]))\n",
        "\n",
        "    dataloader_training = DataLoader(transformed_training, batch_size, shuffle=True, num_workers=num_workers)\n",
        "\n",
        "    return dataloader_training\n",
        "\n",
        "\n",
        "def getEvalData(csv_file='./fashion_mnist_extracted/val.csv', batch_size=64, num_workers=0):\n",
        "    __normalize_stats = {'mean': [0.5], 'std': [0.5]}\n",
        "    # TODO: Part 1.4 (1 point)\n",
        "    transformed_eval = FashionMNISTDataset(csv_file=csv_file,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            RandomWindowDrop(6),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(__normalize_stats['mean'],\n",
        "                                                      __normalize_stats['std'])\n",
        "                                        ]))\n",
        "    \n",
        "    # DataLoader shuffle=False\n",
        "    dataloader_eval = DataLoader(transformed_training, batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return dataloader_eval\n",
        "\n",
        "def getTestData(csv_file='./fashion_mnist_extracted/test.csv', batch_size=64, num_workers=0):\n",
        "    __normalize_stats = {'mean': [0.5], 'std': [0.5]}\n",
        "    # TODO: Part 1.4 (1 point)\n",
        "    transformed_test = FashionMNISTDataset(csv_file=csv_file,\n",
        "                                        transform=transforms.Compose([\n",
        "                                            RandomWindowDrop(6),\n",
        "                                            transforms.ToTensor(),\n",
        "                                            transforms.Normalize(__normalize_stats['mean'],\n",
        "                                                      __normalize_stats['std'])\n",
        "                                        ]))\n",
        "    \n",
        "    # DataLoader shuffle=False\n",
        "    dataloader_test = DataLoader(transformed_training, batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return dataloader_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQOr-u8X10CM"
      },
      "source": [
        "### Part 1.5. Use functions define in **Part 1.4** to actually create our training/validation/testing DataLoaders (<span style=\"color:green\">1 point</span>)  \n",
        "\n",
        "In assignment 3, to load the images and labels from e.g. train_loader, one would call:  \n",
        "```\n",
        "for i, (images, labels) in enumerate(train_loader):\n",
        "    outs = net(images) \n",
        "```\n",
        "***In this assignment, our DataLoader return a dict, so we should call***\n",
        "```\n",
        "for i, sample in enumerate(train_loader):\n",
        "    images, labels = sample['image'], sample['label']\n",
        "    outs = net(images)\n",
        "```  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbOCH_3A10CN"
      },
      "outputs": [],
      "source": [
        "# Set batch_size to 64, shuffling the training set and use 2 workers to do parallel reading.\n",
        "train_loader = getTrainingData(csv_file='./fashion_mnist_extracted/train.csv', batch_size=64, num_workers=4)\n",
        "\n",
        "# TODO: create valid_loader with no shuffling (0.5 points)\n",
        "# batch_size = 64\n",
        "valid_loader = getEvalData(csv_file='./fashion_mnist_extracted/val.csv', batch_size=64, num_workers=4)\n",
        "# TODO: create test_loader with no shuffling (0.5 points)\n",
        "# batch_size = 64\n",
        "test_loader = getTestData(csv_file='./fashion_mnist_extracted/test.csv', batch_size=64, num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGh6Oc5E10CN"
      },
      "source": [
        "## Part 2. Build a CNN on your own (<span style=\"color:green\">1.0 point</span>)\n",
        "Structure of the CNN (**Conv**: convolutional layer, **BN**: Batch Normalization layer, **Max_Pool**: max pooling layer, **FC**: fully connected layer, batch_size=64):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ez5zZQw10CN"
      },
      "source": [
        "To define your own Network, following the rule of thumb:  \n",
        "1. Define the layers in `__init__`.  \n",
        "2. Do the forward calculation in `forward`.  \n",
        "<span style=\"color:red\"> ***Be careful that this model is a little bit different than the model in assignment 3*** </span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lLvrmh710CN"
      },
      "source": [
        "### Fill in the model  (<span style=\"color:green\">1.0 point</span>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgqnlyY_10CO"
      },
      "outputs": [],
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__() \n",
        "\n",
        "        # define layers \n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(6)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        \n",
        "        # TODO: fill the rest part (0.5 points)  \n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=18, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(18)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc3 = nn.Linear(in_features=882, out_features=128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(in_features=128, out_features=10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)     \n",
        "        x = self.max_pool1(x)\n",
        "        \n",
        "        # TODO: fill the rest part, you may need more lines like x = ... (0.5 points)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)     \n",
        "        x = self.max_pool2(x)\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)     \n",
        "        x = self.fc4(x)\n",
        "        \n",
        "        return x\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeaK-XnL10CO"
      },
      "source": [
        "To define a replicate [**resnet-18**](https://arxiv.org/pdf/1512.03385.pdf) model with:  \n",
        "+ The first conv layer take in 1-channel input.\n",
        "+ The last fully connected layer output 10-classes.  \n",
        "***(NOTE: use this model later in Part 3.4)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InRa3xsZ10CO"
      },
      "outputs": [],
      "source": [
        "class ResNet18_Fashion_MNIST(torchvision.models.ResNet):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ResNet18_Fashion_MNIST, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=num_classes)\n",
        "        # Override the \"conv1\" layer from the resnet-18 model\n",
        "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return super(ResNet18_Fashion_MNIST, self).forward(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiR7Gd9-10CP"
      },
      "source": [
        "## Part 3. Train and test your CNN model (<span style=\"color:green\">9.0 points or more</span>)\n",
        "### Part 3.1. Create functions for train and evaluation\n",
        "* Instantiate a network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "_IvGvCot10CP"
      },
      "outputs": [],
      "source": [
        "# Create a train writer and a validation writer\n",
        "# After training, to open tensorboard run\n",
        "# tensorboard --logdir tb_graphs/ --port 5656\n",
        "# The above command use to run a tensorboard for data in ./tb_graphs folder in port 5656\n",
        "writer = SummaryWriter('tb_graphs/training')\n",
        "val_writer = SummaryWriter('tb_graphs/validation')\n",
        "\n",
        "# Switch between models\n",
        "use_resnet18 = False\n",
        "if not use_resnet18:\n",
        "    # instantiate a network\n",
        "    net = Network(num_classes=10)\n",
        "else:\n",
        "    # instantiate ResNet-18 model\n",
        "    net = ResNet18_Fashion_MNIST(num_classes=10)\n",
        "    \n",
        "# Print out the layers of our model\n",
        "print(net)\n",
        "\n",
        "# Get some random training images\n",
        "_iter = iter(train_loader)\n",
        "samples = _iter.next()\n",
        "images = samples['image']\n",
        "\n",
        "# Create grid of images\n",
        "img_grid = torchvision.utils.make_grid(images)\n",
        "\n",
        "# Show images\n",
        "plt.imshow(img_grid.mean(dim=0).cpu().numpy(), cmap=\"Greys\")\n",
        "\n",
        "# Write to tensorboard\n",
        "writer.add_image('train_images', img_grid)\n",
        "\n",
        "# Write model graph to tensorboard\n",
        "writer.add_graph(net, images)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGyUkEjn10CP"
      },
      "source": [
        "### Part 3.2. Training and tensorboard log  (<span style=\"color:green\">3.5 points</span>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7tmoVOR10CP"
      },
      "outputs": [],
      "source": [
        "# evaluation function (not the same as in assignment 3)\n",
        "def eval(net, loss_function, data_loader):\n",
        "    net.eval()\n",
        "    correct = 0.0\n",
        "    num_images = 0.0\n",
        "    running_loss = 0.0\n",
        "    for i, sample in enumerate(data_loader):\n",
        "        # TODO: fill these blanks (0.5 points)\n",
        "        images = images.cuda()\n",
        "        labels= labels.cuda()\n",
        "        outs = net(images)\n",
        "        _, preds = outs.max(1)\n",
        "        correct += preds.eq(labels).sum()\n",
        "        running_loss += loss_function(outs, labels).item()\n",
        "        num_images += len(labels)\n",
        "\n",
        "    acc = correct.float() / num_images\n",
        "    loss = running_loss / len(data_loader)\n",
        "    return acc, loss\n",
        "\n",
        "# training function\n",
        "def train(net, train_loader, valid_loader, writer, val_writer, loss_function):\n",
        "    # TODO: build your SGD optimizer with learning rate=0.01, momentum=0.9, no weight decay (0.5 points)\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=False) #fill the blank bracket\n",
        "\n",
        "    # Log training process to tensorboard every 100 iterations\n",
        "    log_every = 100\n",
        "    # Training for 20 epochs (you can modify this)\n",
        "    epoches = 20\n",
        "    for epoch in range(epoches):\n",
        "        start_t = time.time()\n",
        "        net.train() \n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        for i, sample in enumerate(train_loader):\n",
        "            # TODO: fill these blanks  (0.5 points)\n",
        "            images = images.cuda()\n",
        "            labels= labels.cuda()\n",
        "            outs = net(images)\n",
        "            loss = running_loss / len(data_loader)\n",
        "            _, preds = outs.max(1)\n",
        "            correct = preds.eq(labels).sum()\n",
        "            running_acc += correct.float() / len(labels)\n",
        "            \n",
        "            # TODO: clear grads, back-propagation, backward propogation, update parameters (0.5 points)\n",
        "            \n",
        "                        \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            \n",
        "            if i % log_every == 99: \n",
        "                \n",
        "                print('[Epoch/iter]: [{}/{}], loss: {:.05f}, accuracy: {:.05f}'.format(epoch, i+1, \n",
        "                           running_loss / log_every, running_acc / log_every))\n",
        "\n",
        "                log_index = epoch * len(train_loader) + i\n",
        "                # Log the training loss and accuracy\n",
        "                # Example of using .add_scalar()\n",
        "                # Note tag='Loss'\n",
        "                writer.add_scalar('Loss', running_loss / log_every, log_index) # tag='Loss'\n",
        "                # TODO: load the training accuracy using writer (0.5 points)\n",
        "                # Note tag='Accuracy'\n",
        "                \n",
        "                \n",
        "\n",
        "                # Log predictions\n",
        "                # Example of using .add_figure()\n",
        "                writer.add_figure('predictions', get_preds_figure(net, images, labels), log_index)\n",
        "                running_loss = 0.0\n",
        "                running_acc = 0.0\n",
        "\n",
        "        \n",
        "        # Running the validation\n",
        "        acc_eval, loss_eval = eval(net, loss_function, valid_loader)\n",
        "        print('Elapsed time: {:.02f} seconds, end of epoch: {}, lr: {}, val_loss: {:.05f}, val_acc: {:.05f}'.format(\n",
        "            time.time()-start_t, epoch, optimizer.param_groups[0]['lr'], loss_eval, acc_eval))\n",
        "        # Log the validation loss and accuracy\n",
        "        # TODO: load the validation loss using val_writer (0.5 points)\n",
        "        # Using val_writer will log the values to the validation writer\n",
        "        # Note tag='Loss'\n",
        "        val_writer.add_scalar('Loss', loss_eval, log_index)\n",
        "            \n",
        "        # TODO: load the validation accuracy using val_writer (0.5 points)\n",
        "        # Note tag='Accuracy'\n",
        "        val_writer.add_scalar('Accuracy', acc_eval,log_index)\n",
        "        \n",
        "\n",
        "    return net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5V8f1qx10CQ"
      },
      "source": [
        "### Part 3.3. Tensorboard visualization  (<span style=\"color:green\">1.0 point</span>)\n",
        "#### TODO: Take a picture and report your training+validation loss and accuracy curves here   \n",
        "\n",
        "It should look something similar to this. (not exactly but similar)  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**AGAIN: after training, to open tensorboard run**\n",
        "```\n",
        "tensorboard --logdir tb_graphs/ --port 5656\n",
        "```\n",
        "The above command use to run a tensorboard for data in **./tb_graphs** folder in port **5656**\n",
        "\n",
        "\n",
        "\n",
        "**NOTE: to add the image to this report.**\n",
        "1. Take a screenshot of your tensorboard\n",
        "2. Save the screenshot image\n",
        "3. Drag and drop the image into this markdown cell\n",
        "\n",
        "----->   Drag and drop the image below this line!!   <-----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pyCLH3a10CQ"
      },
      "source": [
        "### Part 3.4. Train and test your network (<span style=\"color:green\">1.0 point</span>)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "hdB8BgZA10CQ"
      },
      "outputs": [],
      "source": [
        "print('Please wait patiently, it may take some seconds...')\n",
        "# TODO: train your network here (0.5 points)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Save the weight of current model to disk\n",
        "PATH = './net.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "# Load the model weights from './net.pth'\n",
        "net.load_state_dict(torch.load('./net.pth'))\n",
        "\n",
        "\n",
        "# TODO: test your network here on testing data (0.5 points)\n",
        "acc_test,_ =\n",
        "print('Accuracy on testing data: {:.05f}'.format(acc_test))\n",
        "\n",
        "# Close the training and validation writer\n",
        "writer.close()\n",
        "val_writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgU9QZ3710CQ"
      },
      "source": [
        "### Part 3.5. Train and test using the resnet-18 model (<span style=\"color:green\">1.5 points</span>)  \n",
        "**To use the resnet-18 model, you can set:** (This model will take longer training time)\n",
        "```\n",
        "use_resnet18 = True\n",
        "```\n",
        "\n",
        "Remember to resize the input image from (28x28) -> (224x224) before convert it to pytorch tensor. To resize the PIL image, you can use e.g. [transform.Resize()](https://pytorch.org/docs/stable/torchvision/transforms.html)  \n",
        "```\n",
        "torchvision.transforms.Resize(size, interpolation=2)\n",
        "```\n",
        "Something for example:\n",
        "```\n",
        "transform=transforms.Compose([\n",
        "                        RandomWindowDrop(6),\n",
        "                        transforms.Resize(224),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize(__normalize_stats['mean'], __normalize_stats['std'])\n",
        "                            ])\n",
        "```\n",
        "and we have to **resize** for **training/validation/testing DataLoader**\n",
        "\n",
        "Accuracy on testing data: ??? (<span style=\"color:green\">0.5 points</span>)\n",
        "\n",
        "Report your training+validation loss and accuracy tensorboard curves of the resnet-18 model (<span style=\"color:green\">1.0 point</span>)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTVCL0FQ10CQ"
      },
      "source": [
        "### Part 3.7. Ideas on improving the testing accuracy (<span style=\"color:green\">0.5 points</span>)\n",
        "#### Your answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqK91DEs10CR"
      },
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Assignment_4 _subam_chauhan_2771463.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}